---
title: "Forming Galaxies using Machine Learning(ongoing)"
excerpt: "<br/><img src='/files/images/dark1.png'>"
collection: 'research'
permalink: /research/dark
venue: "Flatiron Institute"
date: 2018-09-10 - present
location: "New York, US"
---
Designed a 3D Recurrent Residual Convolutional Neural Network based on U-net models(R2U-net) and 3D Convolutional Neural Nets with inception modules to predict the count of the galaxies in each voxel based on the dark matter density distribution at a given redshift(age).


[Poster](http://yueqiusun.github.io/files/1006_poster.pdf)

<!-- Method
======
Designed 3D Convolution Neural Nets with inception modules with different architectures and 3D R2Unet to predict parameters for Full Hydrodynamic Simulation based on the simulation on dark matter density distribution at a certain redshift (age). 
Background
======
The project is one of the most challenging and interesting project in the interface of physics and machine learning. Physicists have spend ages in accumulating "physical intuitions" through their training. Machine Learning has recently be touted to be able to probably learn "science" without the guide of humans or scientists for scientific problems.


One may wonder what would happen if one combines physical intuition and the power of machine learning, in particular deep neural network. What happens if we impose rotational, translational invariance that is inherent in the training set directly instead of letting the system learn it by itself?


There have been a bit of literature on implementing what we think is inherent in the system into the NN, however, there are a lot more to be done.


Cosmology has a lot of physical laws and rules we can implement onto our deep NN that can in principle significantly improve our results in prediction.



This is a riskier project, but probably have a higher return than most projects in physics alone, since it will lead the way in understanding how one can put in intuitions or existing knowledge directly into the network instead of through training sets.


The data will be real and complex numbers as a function of frequency (radio frequency) and time. The data set will be astrophysical in nature, but also has interference from tele-communications, radio, TV.


The size of the dataset can range from a few TB to a few PB (depending on how much we need to generate realistic mock datasets). -->

